{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive"
      ],
      "metadata": {
        "id": "9Z4A7esNNhx4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuWZJHStNbIU"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Cell 1 — Mount Drive\n",
        "# =========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "UD5JfI9s8SQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# Cell 2 — Imports\n",
        "# =========================\n",
        "import os, math, re, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import LineString, MultiLineString, Polygon, MultiPolygon, Point\n",
        "from pandas.api.types import is_datetime64_any_dtype, is_datetime64tz_dtype\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"shapely\")\n"
      ],
      "metadata": {
        "id": "vPZr5dWD8Ts4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the Parameters and Paths. Do parameters for what it takes to be a crosswalk, clustering radius sizes, and # of segments it takes to be considered an intersection"
      ],
      "metadata": {
        "id": "lCfJ7Y9y83Uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================\n",
        "# Cell 3 — Paths & Parameters\n",
        "# =================================\n",
        "\n",
        "# Paths\n",
        "CRASHES_PATH        = \"/content/drive/My Drive/Crashes_in_DC.csv\"\n",
        "SPEED_GEOJSON_PATH  = \"/content/drive/My Drive/Roadway_SubBlock.geojson\"  # DDOT lines\n",
        "PEDESTRIAN_PATH     = \"/content/drive/My Drive/Sidewalks.geojson\"         # sidewalks + crosswalks (lines/polys)\n",
        "OUT_DIR             = \"/content/drive/My Drive/outputs_intersections\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Filters\n",
        "DATE_START, DATE_END = \"2020-01-01\", \"2025-04-30\"\n",
        "MAR_MIN = 100  # set None to disable\n",
        "\n",
        "# CRS\n",
        "CRS_LL = 4326\n",
        "CRS_M  = 3857\n",
        "\n",
        "# Road model\n",
        "DEFAULT_ROAD_HALF_WIDTH_M = 15.0  # for road buffers in crosswalk test\n",
        "\n",
        "# Crosswalk geometry rules\n",
        "MIN_CROSSWALK_LEN_M = 2.5\n",
        "MAX_CROSSWALK_LEN_M = 60.0\n",
        "ANGLE_MIN_DEG, ANGLE_MAX_DEG = 40, 140   # ~perpendicular to road\n"
      ],
      "metadata": {
        "id": "jUNwnpBC83vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helpers:\n",
        "_bearing_deg: gets a direction (0–180°) for any line, ignoring which way it was drawn.\n",
        "\n",
        "_angle_diff: returns the smallest angle between two bearings (0–90°).\n",
        "\n",
        "_midpoint / _endpoints: quickly grab the middle point and the two ends of a line.\n",
        "\n",
        "_lines_from_any: converts polygons/multilines to simple LineStrings (2D), preserving attributes — ensures everything is line geometry for later checks."
      ],
      "metadata": {
        "id": "pC4AxB5d84l0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 4 — Helpers\n",
        "# =========================\n",
        "\n",
        "def _drop_zm_line(ls: LineString):\n",
        "    \"\"\"Return a 2D LineString (drop Z/M). None if degenerate.\"\"\"\n",
        "    if ls is None or not hasattr(ls, \"coords\"):\n",
        "        return None\n",
        "    coords2d = [(c[0], c[1]) for c in ls.coords if len(c) >= 2]\n",
        "    if len(coords2d) < 2:\n",
        "        return None\n",
        "    if all(coords2d[0] == c for c in coords2d[1:]):\n",
        "        return None\n",
        "    return LineString(coords2d)\n",
        "\n",
        "def lines_from_any_preserve_attrs(gdf):\n",
        "    \"\"\"\n",
        "    Convert polygons/multilines to LineStrings while preserving non-geometry columns.\n",
        "    Explodes Multi* into single LineStrings; forces 2D.\n",
        "    \"\"\"\n",
        "    if gdf is None or gdf.empty:\n",
        "        return gpd.GeoDataFrame(geometry=gpd.GeoSeries([], crs=gdf.crs))\n",
        "    rows = []\n",
        "    cols = [c for c in gdf.columns if c != \"geometry\"]\n",
        "    for _, row in gdf.iterrows():\n",
        "        geom = row.geometry\n",
        "        base = row[cols].to_dict()\n",
        "        if geom is None:\n",
        "            continue\n",
        "        if isinstance(geom, (Polygon, MultiPolygon)):\n",
        "            b = geom.boundary\n",
        "            geoms = list(b.geoms) if isinstance(b, MultiLineString) else [b]\n",
        "        elif isinstance(geom, MultiLineString):\n",
        "            geoms = list(geom.geoms)\n",
        "        elif isinstance(geom, LineString):\n",
        "            geoms = [geom]\n",
        "        else:\n",
        "            continue\n",
        "        for ls in geoms:\n",
        "            ls2 = _drop_zm_line(ls)\n",
        "            if ls2 is not None and not ls2.is_empty and ls2.length > 0:\n",
        "                rec = dict(base)\n",
        "                rec[\"geometry\"] = ls2\n",
        "                rows.append(rec)\n",
        "    if not rows:\n",
        "        return gpd.GeoDataFrame(geometry=gpd.GeoSeries([], crs=gdf.crs))\n",
        "    out = gpd.GeoDataFrame(rows, crs=gdf.crs).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "def _bearing_degrees(ls: LineString) -> float:\n",
        "    \"\"\"Return 0..180 bearing using endpoints (directionless, 2D).\"\"\"\n",
        "    if ls is None or not hasattr(ls, \"coords\") or len(ls.coords) < 2:\n",
        "        return np.nan\n",
        "    x0, y0 = ls.coords[0][0], ls.coords[0][1]\n",
        "    x1, y1 = ls.coords[-1][0], ls.coords[-1][1]\n",
        "    if (x1 == x0) and (y1 == y0):\n",
        "        return np.nan\n",
        "    ang = math.degrees(math.atan2((x1 - x0), (y1 - y0)))\n",
        "    return abs(ang) % 180.0\n",
        "\n",
        "def _angle_diff(a, b):\n",
        "    \"\"\"Smallest angle between two bearings (0..90).\"\"\"\n",
        "    if pd.isna(a) or pd.isna(b):\n",
        "        return np.nan\n",
        "    d = abs(a - b) % 180.0\n",
        "    return d if d <= 90 else 180 - d\n",
        "\n",
        "def _segment_midpoint(ls: LineString) -> Point:\n",
        "    try:\n",
        "        return ls.interpolate(0.5, normalized=True)\n",
        "    except Exception:\n",
        "        x0, y0 = ls.coords[0][0], ls.coords[0][1]\n",
        "        x1, y1 = ls.coords[-1][0], ls.coords[-1][1]\n",
        "        return Point((x0+x1)/2.0, (y0+y1)/2.0)\n",
        "\n",
        "def _endpoints(ls: LineString):\n",
        "    x0, y0 = ls.coords[0][0], ls.coords[0][1]\n",
        "    x1, y1 = ls.coords[-1][0], ls.coords[-1][1]\n",
        "    return Point(x0, y0), Point(x1, y1)\n",
        "\n",
        "def _dedupe_left(df):\n",
        "    \"\"\"Keep first left row after sjoin_nearest ties/dups.\"\"\"\n",
        "    return df[~df.index.duplicated(keep=\"first\")].copy()\n"
      ],
      "metadata": {
        "id": "PArCo6Eg857w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load & Prep the Pedestrian Crashes and apply filtering. Also, only keep accidents that involve pedestrians"
      ],
      "metadata": {
        "id": "n1TTsI1_84Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# Cell 5 — Load & Prep Crashes (ped-only)\n",
        "# =====================================\n",
        "\n",
        "df = pd.read_csv(CRASHES_PATH, dtype={\"STREETSEGID\": str}, low_memory=False)\n",
        "\n",
        "# Clean lat/lon\n",
        "df = df.dropna(subset=[\"LATITUDE\",\"LONGITUDE\"]).copy()\n",
        "df[\"LATITUDE\"]  = pd.to_numeric(df[\"LATITUDE\"], errors=\"coerce\")\n",
        "df[\"LONGITUDE\"] = pd.to_numeric(df[\"LONGITUDE\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"LATITUDE\",\"LONGITUDE\"]).copy()\n",
        "\n",
        "# Date filter (UTC-aware safe)\n",
        "df[\"FROMDATE\"] = pd.to_datetime(df[\"FROMDATE\"], errors=\"coerce\", utc=True)\n",
        "df = df[(df[\"FROMDATE\"] >= DATE_START) & (df[\"FROMDATE\"] <= DATE_END)].copy()\n",
        "\n",
        "# MAR filter\n",
        "if \"MAR_SCORE\" in df.columns and MAR_MIN is not None:\n",
        "    df[\"MAR_SCORE\"] = pd.to_numeric(df[\"MAR_SCORE\"], errors=\"coerce\")\n",
        "    df = df[df[\"MAR_SCORE\"] >= MAR_MIN].copy()\n",
        "\n",
        "# Injury fields fill (for later, optional)\n",
        "injury_cols = [\n",
        "    \"MAJORINJURIES_BICYCLIST\",\"MINORINJURIES_BICYCLIST\",\"UNKNOWNINJURIES_BICYCLIST\",\"FATAL_BICYCLIST\",\n",
        "    \"MAJORINJURIES_DRIVER\",\"MINORINJURIES_DRIVER\",\"UNKNOWNINJURIES_DRIVER\",\"FATAL_DRIVER\",\n",
        "    \"MAJORINJURIES_PEDESTRIAN\",\"MINORINJURIES_PEDESTRIAN\",\"UNKNOWNINJURIES_PEDESTRIAN\",\"FATAL_PEDESTRIAN\",\n",
        "    \"FATALPASSENGER\",\"MAJORINJURIESPASSENGER\",\"MINORINJURIESPASSENGER\",\n",
        "    \"MAJORINJURIESOTHER\",\"MINORINJURIESOTHER\",\"FATALOTHER\"\n",
        "]\n",
        "for c in injury_cols:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
        "    else:\n",
        "        df[c] = 0\n",
        "\n",
        "# Pedestrian-only subset\n",
        "ped_cols = [\"MAJORINJURIES_PEDESTRIAN\",\"MINORINJURIES_PEDESTRIAN\",\"UNKNOWNINJURIES_PEDESTRIAN\",\"FATAL_PEDESTRIAN\"]\n",
        "df_ped = df[df[ped_cols].sum(axis=1) > 0].copy()\n",
        "\n",
        "# GeoDataFrame to meters\n",
        "gdf_ped_4326 = gpd.GeoDataFrame(\n",
        "    df_ped, geometry=gpd.points_from_xy(df_ped[\"LONGITUDE\"], df_ped[\"LATITUDE\"]), crs=CRS_LL\n",
        ")\n",
        "gdf_ped_m = gdf_ped_4326.to_crs(CRS_M)\n",
        "\n",
        "print(f\"Ped crashes loaded: {len(gdf_ped_m)}\")\n"
      ],
      "metadata": {
        "id": "nZm-t1wX89_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load DDOT lines"
      ],
      "metadata": {
        "id": "4q79r4YT86Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Cell 6 — Load DDOT lines (Roadway_SubBlock) → to 3857 lines\n",
        "# ==========================================================\n",
        "\n",
        "roads = gpd.read_file(SPEED_GEOJSON_PATH)\n",
        "if roads.crs is None:\n",
        "    roads = roads.set_crs(CRS_LL)\n",
        "roads_m = roads.to_crs(CRS_M)\n",
        "\n",
        "roads_lines = lines_from_any_preserve_attrs(roads_m)\n",
        "roads_lines[\"road_bearing\"] = roads_lines.geometry.apply(_bearing_degrees)\n",
        "\n",
        "print(f\"DDOT road lines: {len(roads_lines)}\")\n"
      ],
      "metadata": {
        "id": "6zDXUWsS86jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in the crosswalks+sidewalks"
      ],
      "metadata": {
        "id": "fnRQr4ko87Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# Cell 7 — Load crosswalk/sidewalk layer → to 3857\n",
        "# ===============================================\n",
        "\n",
        "ped_raw = gpd.read_file(PEDESTRIAN_PATH)\n",
        "if ped_raw.crs is None:\n",
        "    ped_raw = ped_raw.set_crs(CRS_LL)\n",
        "ped_m_raw = ped_raw.to_crs(CRS_M)\n",
        "\n",
        "# force to single LineStrings (handles polys/multilines)\n",
        "ped_lines = lines_from_any_preserve_attrs(ped_m_raw)\n",
        "ped_lines[\"length_m\"] = ped_lines.length\n",
        "ped_lines[\"bearing\"]  = ped_lines.geometry.apply(_bearing_degrees)\n",
        "\n",
        "print(f\"Pedestrian lines (raw→lines): {len(ped_lines)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "5L18HGSp87bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds the nearest road for each pedestrian line and brings over that road’s bearing.\n",
        "\n",
        "Runs the three tests:\n",
        "\n",
        "\n",
        "\n",
        "Angle: pedestrian line is roughly perpendicular to the road (within your angle band).\n",
        "\n",
        "Length: between your min/max length thresholds.\n",
        "\n",
        "Placement: line’s midpoint inside a buffered roadway; endpoints outside (curbs).\n",
        "\n",
        "\n",
        "\n",
        "Marks lines that pass all three as crosswalks; everything else stays as sidewalk/other.\n",
        "\n",
        "Produces two working sets: crosswalks and sidewalks."
      ],
      "metadata": {
        "id": "5nmK7XkR87rg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oXm3QOaY88Yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# Cell 8 — Figure out if crosswalk or not (attr + geometry test)\n",
        "# ==============================================================\n",
        "\n",
        "# (A) Attribute hint: look for text cues such as \"crosswalk/crossing/xing/zebra/marked x\"\n",
        "text_cols = [c for c in ped_lines.columns if c != \"geometry\" and pd.api.types.is_string_dtype(ped_lines[c])]\n",
        "needle = re.compile(r\"(crosswalk|crossing|xing|zebra|marked\\s*x)\", re.I)\n",
        "\n",
        "def _attr_crosswalk(row):\n",
        "    for c in text_cols:\n",
        "        v = row.get(c)\n",
        "        if isinstance(v, str) and needle.search(v):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "ped_lines[\"attr_is_crosswalk\"] = ped_lines.apply(_attr_crosswalk, axis=1)\n",
        "\n",
        "# (B) Geometry test: nearest road, check angle & length, and that the segment MIDPOINT sits over the road,\n",
        "# but endpoints lie off the road buffer (i.e., spans across)\n",
        "join = gpd.sjoin_nearest(\n",
        "    ped_lines, roads_lines[[\"geometry\",\"road_bearing\"]],\n",
        "    how=\"left\", distance_col=\"dist_to_road_m\"\n",
        ")\n",
        "join = _dedupe_left(join)\n",
        "idx_cols = [c for c in join.columns if c.startswith(\"index_right\")]\n",
        "if idx_cols:\n",
        "    join = join.rename(columns={idx_cols[0]: \"road_idx\"})\n",
        "else:\n",
        "    join[\"road_idx\"] = pd.NA\n",
        "\n",
        "join[\"road_geom\"]    = join[\"road_idx\"].map(roads_lines[\"geometry\"]) if join[\"road_idx\"].notna().any() else None\n",
        "join[\"road_bearing\"] = join[\"road_idx\"].map(roads_lines[\"road_bearing\"]) if join[\"road_idx\"].notna().any() else np.nan\n",
        "\n",
        "def _classify_row(r):\n",
        "    ls: LineString = r.geometry\n",
        "    rg = r.get(\"road_geom\", None)\n",
        "    rb = r.get(\"road_bearing\", np.nan)\n",
        "    if ls is None or rg is None or pd.isna(rb):\n",
        "        return pd.Series({\"angle_diff\": np.nan, \"mid_in\": False, \"a_in\": False, \"b_in\": False,\n",
        "                          \"len_ok\": False, \"ang_ok\": False, \"geo_crosswalk\": False})\n",
        "\n",
        "    ang_ped = r[\"bearing\"]\n",
        "    ad = _angle_diff(ang_ped, rb)\n",
        "\n",
        "    # Road buffer to approximate carriageway\n",
        "    road_buf = rg.buffer(DEFAULT_ROAD_HALF_WIDTH_M, cap_style=2, join_style=2)\n",
        "\n",
        "    mid = _segment_midpoint(ls)\n",
        "    a, b = _endpoints(ls)\n",
        "    mid_in = road_buf.contains(mid)\n",
        "    a_in   = road_buf.contains(a)\n",
        "    b_in   = road_buf.contains(b)\n",
        "\n",
        "    length_ok = (r[\"length_m\"] >= MIN_CROSSWALK_LEN_M) and (r[\"length_m\"] <= MAX_CROSSWALK_LEN_M)\n",
        "    angle_ok  = (not pd.isna(ad)) and (ad >= ANGLE_MIN_DEG) and (ad <= ANGLE_MAX_DEG)\n",
        "\n",
        "    geo_cross = bool(length_ok and angle_ok and mid_in and (not a_in) and (not b_in))\n",
        "    return pd.Series({\"angle_diff\": ad, \"mid_in\": mid_in, \"a_in\": a_in, \"b_in\": b_in,\n",
        "                      \"len_ok\": length_ok, \"ang_ok\": angle_ok, \"geo_crosswalk\": geo_cross})\n",
        "\n",
        "tests = join.apply(_classify_row, axis=1)\n",
        "ped_class = pd.concat([join, tests], axis=1)\n",
        "\n",
        "# Final label\n",
        "ped_class[\"CLASS\"] = np.where(ped_class[\"attr_is_crosswalk\"] | ped_class[\"geo_crosswalk\"], \"CROSSWALK\", \"SIDEWALK\")\n",
        "\n",
        "crosswalks_m = ped_class[ped_class[\"CLASS\"] == \"CROSSWALK\"].copy()\n",
        "sidewalks_m  = ped_class[ped_class[\"CLASS\"] == \"SIDEWALK\"].copy()\n",
        "\n",
        "print(\"\\n=== Crosswalk classification summary ===\")\n",
        "print(f\"Total ped segments: {len(ped_class)}\")\n",
        "print(f\"  Attribute-hinted crosswalks: {int(ped_class['attr_is_crosswalk'].sum())}\")\n",
        "print(f\"  Geometry-pass crosswalks:    {int(ped_class['geo_crosswalk'].sum())}\")\n",
        "print(f\"  FINAL CROSSWALKS:            {len(crosswalks_m)}\")\n",
        "print(f\"  FINAL SIDEWALKS:             {len(sidewalks_m)}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iHMRFjnJ88-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "build the intersections using ddot"
      ],
      "metadata": {
        "id": "ovt4Lz-3m8zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 9 — Build intersections (snap endpoints & compute degree)\n",
        "# =========================\n",
        "\n",
        "# Safe defaults in case not set earlier\n",
        "SNAP_TOL_M          = globals().get(\"SNAP_TOL_M\", 6.0)\n",
        "NODE_TOUCH_TOL_M    = globals().get(\"NODE_TOUCH_TOL_M\", 1.5)\n",
        "MIN_INTERSECTION_DEG= globals().get(\"MIN_INTERSECTION_DEG\", 3)\n",
        "CRS_M               = globals().get(\"CRS_M\", 3857)\n",
        "\n",
        "# 1) Extract endpoints from road LineStrings\n",
        "end_pts = []\n",
        "for i, geom in enumerate(roads_lines.geometry):\n",
        "    if geom is None or geom.is_empty or not isinstance(geom, LineString) or len(geom.coords) < 2:\n",
        "        continue\n",
        "    x0, y0 = geom.coords[0]\n",
        "    x1, y1 = geom.coords[-1]\n",
        "    end_pts.append({\"road_idx\": i, \"geometry\": Point(x0, y0)})\n",
        "    end_pts.append({\"road_idx\": i, \"geometry\": Point(x1, y1)})\n",
        "\n",
        "end_pts_g = gpd.GeoDataFrame(end_pts, crs=CRS_M)\n",
        "\n",
        "if end_pts_g.empty:\n",
        "    nodes_deg = gpd.GeoDataFrame(columns=[\"degree\"], geometry=gpd.GeoSeries([], crs=CRS_M))\n",
        "else:\n",
        "    # 2) SNAP: cluster endpoints within SNAP_TOL_M using DBSCAN (min_samples=1)\n",
        "    from sklearn.cluster import DBSCAN\n",
        "    XY = np.c_[end_pts_g.geometry.x.values, end_pts_g.geometry.y.values]\n",
        "    labels = DBSCAN(eps=SNAP_TOL_M, min_samples=1, metric=\"euclidean\", n_jobs=-1).fit_predict(XY)\n",
        "    end_pts_g[\"node_id\"] = labels\n",
        "\n",
        "    # Cluster centroids\n",
        "    nodes = (\n",
        "        end_pts_g.groupby(\"node_id\")\n",
        "                 .agg(x=(\"geometry\", lambda s: np.mean([p.x for p in s])),\n",
        "                      y=(\"geometry\", lambda s: np.mean([p.y for p in s])))\n",
        "                 .reset_index()\n",
        "    )\n",
        "    nodes_g = gpd.GeoDataFrame(nodes, geometry=gpd.points_from_xy(nodes[\"x\"], nodes[\"y\"], crs=CRS_M))\n",
        "\n",
        "    # 3) DEGREE: count distinct road segments that intersect a tiny buffer around node\n",
        "    nodes_buf = nodes_g.copy()\n",
        "    nodes_buf[\"geometry\"] = nodes_buf.buffer(NODE_TOUCH_TOL_M)\n",
        "    join_deg = gpd.sjoin(roads_lines[[\"geometry\"]].reset_index().rename(columns={\"index\":\"road_idx\"}),\n",
        "                         nodes_buf[[\"node_id\",\"geometry\"]],\n",
        "                         how=\"right\", predicate=\"intersects\")\n",
        "    deg = (join_deg.groupby(\"node_id\")[\"road_idx\"].nunique()\n",
        "                    .rename(\"degree\").reset_index())\n",
        "    nodes_deg = nodes_g.merge(deg, on=\"node_id\", how=\"left\").fillna({\"degree\": 0})\n",
        "    nodes_deg[\"degree\"] = nodes_deg[\"degree\"].astype(int)\n",
        "\n",
        "# Keep real intersections (degree ≥ MIN_INTERSECTION_DEG)\n",
        "intersections_m = nodes_deg[nodes_deg[\"degree\"] >= MIN_INTERSECTION_DEG].copy()\n",
        "\n",
        "print(f\"Built intersections: {len(intersections_m)} (degree ≥ {MIN_INTERSECTION_DEG}) / all nodes: {len(nodes_deg)}\")\n"
      ],
      "metadata": {
        "id": "hyZfQllYnBd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tag interesections with crosswalks nearby or not(within 25 meters which was just a value that made sense because it is just a little bigger than a typical intersection, bigger lanes are about 12 feet in width, so 25 meters is about the size of 7 lanes. This would be the size of a massive intersection, but it makes sense for it to be larger because that crosswalk would definitely be part of the same intersection because it is 25 meters away)"
      ],
      "metadata": {
        "id": "5YE-LJOBnHDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 10 — HARD RESET + recompute =====\n",
        "\n",
        "CRS_M = 3857\n",
        "XWALK_THRESHOLD_M = 25.0\n",
        "\n",
        "def _strip_indexish(df):\n",
        "    return df.drop(columns=[c for c in df.columns if c==\"index\" or c.startswith(\"index_\") or c in (\"index_left\",\"index_right\")],\n",
        "                   errors=\"ignore\").reset_index(drop=True)\n",
        "\n",
        "# 0) Rebuild CROSSWALK POINTS from ped_class (robust to prior state)\n",
        "#    (Assumes you already ran Cells 7–8 so ped_class exists)\n",
        "assert 'ped_class' in globals(), \"ped_class not found; run Cells 7–8 first.\"\n",
        "crosswalks_m = ped_class[ped_class[\"CLASS\"] == \"CROSSWALK\"].copy()\n",
        "if not crosswalks_m.empty:\n",
        "    if \"midpoint\" not in crosswalks_m.columns:\n",
        "        crosswalks_m[\"midpoint\"] = crosswalks_m.geometry.apply(_segment_midpoint)\n",
        "    crosswalk_pts_m = gpd.GeoDataFrame(\n",
        "        crosswalks_m.drop(columns=[\"geometry\"]).copy(),\n",
        "        geometry=gpd.GeoSeries(crosswalks_m[\"midpoint\"], crs=crosswalks_m.crs)\n",
        "    )\n",
        "else:\n",
        "    crosswalk_pts_m = gpd.GeoDataFrame(geometry=gpd.GeoSeries([], crs=CRS_M))\n",
        "\n",
        "# 1) Rebuild INTERSECTIONS from nodes_deg (prevents using a previously filtered set)\n",
        "#    (Assumes Cell 9 ran and nodes_deg exists)\n",
        "assert 'nodes_deg' in globals(), \"nodes_deg not found; run Cell 9 first.\"\n",
        "MIN_INTERSECTION_DEG = globals().get(\"MIN_INTERSECTION_DEG\", 3)\n",
        "intersections_m = nodes_deg[nodes_deg[\"degree\"] >= MIN_INTERSECTION_DEG].copy()\n",
        "\n",
        "# 2) Clean + align CRS\n",
        "crosswalk_pts_m = _strip_indexish(crosswalk_pts_m)\n",
        "intersections_m = _strip_indexish(intersections_m)\n",
        "\n",
        "if crosswalk_pts_m.crs != CRS_M and crosswalk_pts_m.crs is not None:\n",
        "    crosswalk_pts_m = crosswalk_pts_m.to_crs(CRS_M)\n",
        "if intersections_m.crs != CRS_M and intersections_m.crs is not None:\n",
        "    intersections_m = intersections_m.to_crs(CRS_M)\n",
        "if intersections_m.crs is None:\n",
        "    intersections_m.set_crs(CRS_M, inplace=True)\n",
        "if crosswalk_pts_m.crs is None:\n",
        "    crosswalk_pts_m.set_crs(CRS_M, inplace=True)\n",
        "\n",
        "# 3) Nearest distance (NO max_distance; always get a distance)\n",
        "if intersections_m.empty or crosswalk_pts_m.empty:\n",
        "    intersections_m[\"dist_to_crosswalk_mid_m\"] = np.nan\n",
        "else:\n",
        "    tag = gpd.sjoin_nearest(\n",
        "        intersections_m,\n",
        "        crosswalk_pts_m[[\"geometry\"]],\n",
        "        how=\"left\",\n",
        "        distance_col=\"dist_to_crosswalk_mid_m\"\n",
        "    )\n",
        "    intersections_m = _strip_indexish(tag)\n",
        "\n",
        "# 4) Threshold → flag\n",
        "intersections_m[\"dist_to_crosswalk_mid_m\"] = pd.to_numeric(intersections_m[\"dist_to_crosswalk_mid_m\"], errors=\"coerce\")\n",
        "intersections_m[\"has_crosswalk_nearby\"] = intersections_m[\"dist_to_crosswalk_mid_m\"].le(XWALK_THRESHOLD_M)\n",
        "\n",
        "# 5) Quick sanity\n",
        "print(f\"Crosswalk segments: {len(crosswalks_m)} | Crosswalk points: {len(crosswalk_pts_m)}\")\n",
        "print(f\"Intersections total: {len(intersections_m)}\")\n",
        "print(f\"Within {XWALK_THRESHOLD_M} m: {int(intersections_m['has_crosswalk_nearby'].sum())}\")\n",
        "print(intersections_m[\"dist_to_crosswalk_mid_m\"].describe())\n",
        "\n"
      ],
      "metadata": {
        "id": "wFRavgjxoAAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split intersections into what has crosswalks nearby and what does not"
      ],
      "metadata": {
        "id": "3m9wjNj93N5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# Cell 11 — Split nodes into with-crosswalk vs no-crosswalk\n",
        "# ===========================================================\n",
        "\n",
        "ints_with_xwalk = intersections_m[intersections_m[\"has_crosswalk_nearby\"]].copy()\n",
        "ints_no_xwalk   = intersections_m[~intersections_m[\"has_crosswalk_nearby\"]].copy()\n",
        "\n",
        "print(f\"Intersections with crosswalk: {len(ints_with_xwalk)}\")\n",
        "print(f\"Intersections without crosswalk: {len(ints_no_xwalk)}\")\n"
      ],
      "metadata": {
        "id": "c4UDA1eT3afC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only look at interesections that have no crosswalks"
      ],
      "metadata": {
        "id": "GOEzvM8pq-Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Keep only intersections without crosswalks ---\n",
        "intersections_m = intersections_m[~intersections_m[\"has_crosswalk_nearby\"]].copy()\n",
        "print(f\"Remaining intersections (no crosswalk nearby): {len(intersections_m)}\")"
      ],
      "metadata": {
        "id": "vF4QuyxJ3Ml-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 12 — Make Buffers at No-Crosswalk Intersections\n",
        "\n",
        "-Creates circular buffers (e.g., 30 m radius) around every intersection without a nearby crosswalk.\n",
        "\n",
        "-Each buffer represents a small “zone of influence” for that intersection.\n",
        "\n",
        "-These will later be used to see how many pedestrian crashes fall inside.-"
      ],
      "metadata": {
        "id": "lo0J7th4A3R3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 12 — Buffers at no-crosswalk intersections\n",
        "# =========================\n",
        "\n",
        "BUFFER_RADIUS_M = globals().get(\"BUFFER_RADIUS_M\", 25.0)  # tweak as you like\n",
        "\n",
        "def _make_buffers(gdf_pts, radius_m, id_col):\n",
        "    if gdf_pts.empty:\n",
        "        return gpd.GeoDataFrame(columns=[id_col], geometry=gpd.GeoSeries([], crs=gdf_pts.crs))\n",
        "    out = gdf_pts.copy()\n",
        "    out[id_col] = np.arange(len(out), dtype=int)\n",
        "    out[\"geometry\"] = out.buffer(radius_m)\n",
        "    return out\n",
        "\n",
        "buf_no_xwalk = _make_buffers(ints_no_xwalk, BUFFER_RADIUS_M, \"buf_id\")\n",
        "print(f\"No-crosswalk buffers: {len(buf_no_xwalk)} (radius={BUFFER_RADIUS_M} m)\")\n"
      ],
      "metadata": {
        "id": "_SFYRcxdA7oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 13 — Join Pedestrian Crashes to Buffers + Compute Severity\n",
        "\n",
        "-Spatially joins all pedestrian crashes to those no-crosswalk buffers.\n",
        "\n",
        "-Calculates a severity score for each crash (weighted by fatal/major/minor injuries).\n",
        "\n",
        "-Aggregates per buffer → gives each buffer:\n",
        "\n",
        "  -number of crashes (n_crashes)\n",
        "\n",
        "  -total crash severity (severity_sum)."
      ],
      "metadata": {
        "id": "vcXZnVBQBBXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 13 — Join ped crashes to buffers + severity (FIXED)\n",
        "# =========================\n",
        "\n",
        "def _ped_severity_single(r):\n",
        "    \"\"\"\n",
        "    Assign ONE severity score per crash, using priority:\n",
        "    - any fatal pedestrian injury -> 7\n",
        "    - else any major pedestrian injury -> 4\n",
        "    - else any minor pedestrian injury -> 1\n",
        "    - else 0\n",
        "    \"\"\"\n",
        "    fatal = float(r.get(\"FATAL_PEDESTRIAN\", 0) or 0)\n",
        "    major = float(r.get(\"MAJORINJURIES_PEDESTRIAN\", 0) or 0)\n",
        "    minor = float(r.get(\"MINORINJURIES_PEDESTRIAN\", 0) or 0)\n",
        "\n",
        "    if fatal > 0:\n",
        "        return 7\n",
        "    elif major > 0:\n",
        "        return 4\n",
        "    elif minor > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Work on a copy to avoid chained-assignment weirdness\n",
        "gdf_ped_m = gdf_ped_m.copy()\n",
        "gdf_ped_m[\"SEVERITY_SCORE_PED\"] = gdf_ped_m.apply(_ped_severity_single, axis=1)\n",
        "\n",
        "# Spatial join: crashes that fall within no-crosswalk buffers\n",
        "crash_in_no = gpd.sjoin(\n",
        "    gdf_ped_m,\n",
        "    buf_no_xwalk[[\"buf_id\", \"geometry\"]],\n",
        "    how=\"inner\",\n",
        "    predicate=\"within\"\n",
        ")\n",
        "\n",
        "# --- Make sure we only count each crash once per buffer ---\n",
        "\n",
        "# Try to detect a crash ID column\n",
        "possible_crash_cols = [\"CRASH_ID\", \"crash_id\", \"CRASH_INDEX\", \"crash_index\", \"OBJECTID\"]\n",
        "crash_col = None\n",
        "for c in possible_crash_cols:\n",
        "    if c in crash_in_no.columns:\n",
        "        crash_col = c\n",
        "        break\n",
        "\n",
        "# If we can't find one, fall back to using the row index as a unique ID\n",
        "if crash_col is None:\n",
        "    crash_in_no = crash_in_no.reset_index().rename(columns={\"index\": \"crash_row\"})\n",
        "    crash_col = \"crash_row\"\n",
        "\n",
        "# Collapse to ONE row per (buffer, crash), using max severity in case of duplicates\n",
        "per_crash = (\n",
        "    crash_in_no\n",
        "    .groupby([\"buf_id\", crash_col], as_index=False)\n",
        "    .agg(SEVERITY_SCORE_PED=(\"SEVERITY_SCORE_PED\", \"max\"))\n",
        ")\n",
        "\n",
        "# Aggregate per buffer:\n",
        "# - n_crashes = number of unique crashes in that buffer\n",
        "# - severity_sum = sum of severity scores (each crash contributes at most 7)\n",
        "agg_no = (\n",
        "    per_crash\n",
        "    .groupby(\"buf_id\", as_index=False)\n",
        "    .agg(\n",
        "        n_crashes=(crash_col, \"nunique\"),\n",
        "        severity_sum=(\"SEVERITY_SCORE_PED\", \"sum\")\n",
        "    )\n",
        ")\n",
        "\n",
        "# Attach back to buffers\n",
        "buf_no_xwalk = buf_no_xwalk.merge(agg_no, on=\"buf_id\", how=\"left\").fillna(\n",
        "    {\"n_crashes\": 0, \"severity_sum\": 0}\n",
        ")\n",
        "\n",
        "print(\"No-crosswalk buffer crash stats (head):\")\n",
        "print(buf_no_xwalk[[\"buf_id\", \"n_crashes\", \"severity_sum\"]].head())\n",
        "\n"
      ],
      "metadata": {
        "id": "wEzGdedABIp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a table based on severity"
      ],
      "metadata": {
        "id": "0e7Mn8QuBpbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "#  Crosswalk Severity Table (RANK, N_CRASHES, SEVERITY_SUM, AVG_LON, AVG_LAT)\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from IPython.display import display\n",
        "\n",
        "MIN_CRASHES_TO_SHOW = globals().get(\"MIN_CRASHES_TO_SHOW\", 0)\n",
        "\n",
        "# --- 1. Start from buf_no_xwalk produced in the previous cell ---\n",
        "table_no_xwalk = buf_no_xwalk.copy()\n",
        "\n",
        "# --- 2. Make sure it's a GeoDataFrame with a CRS ---\n",
        "if not isinstance(table_no_xwalk, gpd.GeoDataFrame):\n",
        "    table_no_xwalk = gpd.GeoDataFrame(table_no_xwalk, geometry=\"geometry\")\n",
        "\n",
        "if table_no_xwalk.crs is None:\n",
        "    # If you KNOW your buffers are in a projected CRS (e.g. EPSG:32618), set that instead.\n",
        "    # For now we assume they are already in lon/lat:\n",
        "    table_no_xwalk = table_no_xwalk.set_crs(epsg=4326)\n",
        "\n",
        "# --- 3. Compute centroids in a projected CRS, then back to lon/lat ---\n",
        "# Use Web Mercator as a simple planar CRS for centroids\n",
        "g_proj = table_no_xwalk.to_crs(epsg=3857)\n",
        "g_proj[\"centroid\"] = g_proj.geometry.centroid\n",
        "\n",
        "# Reproject centroids back to WGS84 (lon/lat)\n",
        "centroids_ll = g_proj.set_geometry(\"centroid\").to_crs(epsg=4326).geometry\n",
        "\n",
        "# Store lon/lat in the original table\n",
        "table_no_xwalk[\"avg_lon\"] = centroids_ll.x\n",
        "table_no_xwalk[\"avg_lat\"] = centroids_ll.y\n",
        "\n",
        "# --- 4. Optional: filter by crash count threshold ---\n",
        "if MIN_CRASHES_TO_SHOW > 0:\n",
        "    table_no_xwalk = table_no_xwalk[\n",
        "        table_no_xwalk[\"n_crashes\"] >= MIN_CRASHES_TO_SHOW\n",
        "    ].copy()\n",
        "\n",
        "# --- 5. Build display table with desired columns ---\n",
        "table_no_xwalk_display = table_no_xwalk[[\"n_crashes\", \"severity_sum\", \"avg_lon\", \"avg_lat\"]]\n",
        "table_no_xwalk_display = table_no_xwalk_display.rename(columns=str.upper)\n",
        "\n",
        "# Sort by severity, then crashes\n",
        "table_no_xwalk_display = table_no_xwalk_display.sort_values(\n",
        "    [\"SEVERITY_SUM\", \"N_CRASHES\"], ascending=[False, False]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "# Add rank column\n",
        "table_no_xwalk_display.insert(0, \"RANK\", np.arange(1, len(table_no_xwalk_display) + 1))\n",
        "\n",
        "print(f\"No-Crosswalk Table (min crashes ≥ {MIN_CRASHES_TO_SHOW}):\")\n",
        "display(table_no_xwalk_display.head(10))\n",
        "\n",
        "# --- 6. Export full table ---\n",
        "table_no_xwalk_display.to_csv(\n",
        "    os.path.join(OUT_DIR, \"no_crosswalk_intersections_table.csv\"),\n",
        "    index=False\n",
        ")\n",
        "print(f\"Saved full table to {OUT_DIR}/no_crosswalk_intersections_table.csv\")\n"
      ],
      "metadata": {
        "id": "uzaxwVrtBq9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map"
      ],
      "metadata": {
        "id": "2kMwcyHaCkIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================================================\n",
        "# Final Map — Crashes (gray), Top 10 Clusters (circles), and Crosswalks (green)\n",
        "# ===========================================================================================\n",
        "\n",
        "import folium\n",
        "from branca.colormap import linear\n",
        "\n",
        "def gdf_geom_only(gdf):\n",
        "    if gdf is None or gdf.empty:\n",
        "        return None\n",
        "    return gpd.GeoDataFrame(geometry=gdf.geometry, crs=gdf.crs).to_crs(4326).to_json()\n",
        "\n",
        "# --- Prep layers in 4326 ---\n",
        "crashes_4326 = gdf_ped_m.to_crs(4326)\n",
        "\n",
        "clusters_src = (\n",
        "    buf_no_xwalk.copy()\n",
        "    if \"buf_no_xwalk\" in globals() and not buf_no_xwalk.empty else\n",
        "    gpd.GeoDataFrame(geometry=gpd.GeoSeries([], crs=\"EPSG:4326\"))\n",
        ")\n",
        "\n",
        "crosswalks_4326 = (\n",
        "    crosswalks_m.to_crs(4326)\n",
        "    if \"crosswalks_m\" in globals() and not crosswalks_m.empty else\n",
        "    gpd.GeoDataFrame(geometry=gpd.GeoSeries([], crs=\"EPSG:4326\"))\n",
        ")\n",
        "\n",
        "# --- Map ---\n",
        "MAP_CENTER = globals().get(\"MAP_CENTER\", [38.9072, -77.0369])\n",
        "MAP_ZOOM   = globals().get(\"MAP_ZOOM\", 12)\n",
        "m = folium.Map(location=MAP_CENTER, zoom_start=MAP_ZOOM, tiles=\"cartodbpositron\")\n",
        "\n",
        "# 1) All crashes (gray) — slightly smaller dots\n",
        "fg_crashes = folium.FeatureGroup(name=\"All pedestrian crashes (gray)\", show=True)\n",
        "for _, r in crashes_4326.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[r.geometry.y, r.geometry.x],\n",
        "        radius=2.0,          # was 2.5 → a tiny bit smaller\n",
        "        color=\"#0d6efd\",\n",
        "        fill=True,\n",
        "        fill_opacity=0.7\n",
        "    ).add_to(fg_crashes)\n",
        "fg_crashes.add_to(m)\n",
        "\n",
        "# 2) Top 10 clusters (≥2 crashes) — solid circles like complete-linkage map\n",
        "fg_clusters = folium.FeatureGroup(name=\"Top 10 clusters (by severity sum)\", show=True)\n",
        "\n",
        "if not clusters_src.empty and \"n_crashes\" in clusters_src.columns and \"severity_sum\" in clusters_src.columns:\n",
        "    # Keep only clusters with ≥2 crashes\n",
        "    clusters_2p = clusters_src[clusters_src[\"n_crashes\"] >= 2].copy()\n",
        "\n",
        "    if not clusters_2p.empty:\n",
        "        # Sort by severity_sum then n_crashes, take top 10\n",
        "        clusters_top = (\n",
        "            clusters_2p\n",
        "            .sort_values([\"severity_sum\", \"n_crashes\"], ascending=[False, False])\n",
        "            .head(10)\n",
        "            .to_crs(4326)\n",
        "        )\n",
        "\n",
        "        # Colormap based on severity_sum (like the other cell)\n",
        "        vmin = float(clusters_top[\"severity_sum\"].min())\n",
        "        vmax = float(clusters_top[\"severity_sum\"].max())\n",
        "        if vmin == vmax:\n",
        "            vmin = 0.0\n",
        "        cmap = linear.Reds_09.scale(vmin, vmax)\n",
        "\n",
        "        for _, r in clusters_top.iterrows():\n",
        "            sev = float(r.get(\"severity_sum\", 0))\n",
        "            ncr = int(r.get(\"n_crashes\", 0))\n",
        "\n",
        "            cen = r.geometry.centroid\n",
        "            lat, lon = float(cen.y), float(cen.x)\n",
        "\n",
        "            # Radius scaled exactly like the complete-linkage centroids:\n",
        "            radius = 6 if vmax == vmin else 6 + 20 * (sev - vmin) / (vmax - vmin)\n",
        "\n",
        "            popup_html = (\n",
        "                f\"<b>Crashes:</b> {ncr}<br>\"\n",
        "                f\"<b>Severity sum:</b> {sev:.1f}<br>\"\n",
        "                f\"<b>Center lon:</b> {lon:.5f}<br>\"\n",
        "                f\"<b>Center lat:</b> {lat:.5f}\"\n",
        "            )\n",
        "\n",
        "            folium.CircleMarker(\n",
        "                location=[lat, lon],\n",
        "                radius=radius,\n",
        "                color=cmap(sev),\n",
        "                fill=True,\n",
        "                fill_color=cmap(sev),\n",
        "                fill_opacity=0.9,\n",
        "                popup=folium.Popup(popup_html, max_width=360),\n",
        "                tooltip=f\"Sev {sev:.1f} | Cr {ncr}\"\n",
        "            ).add_to(fg_clusters)\n",
        "\n",
        "        # Add legend for severity\n",
        "        cmap.caption = \"Cluster severity (severity_sum)\"\n",
        "        cmap.add_to(m)\n",
        "\n",
        "fg_clusters.add_to(m)\n",
        "\n",
        "# 3) All crosswalks (green) — geometry-only to avoid Timestamp serialization issues\n",
        "if not crosswalks_4326.empty:\n",
        "    fg_xwalks = folium.FeatureGroup(name=\"All crosswalks (green)\", show=False)\n",
        "    gj_xwalks = gdf_geom_only(crosswalks_4326)\n",
        "    folium.GeoJson(\n",
        "        gj_xwalks,\n",
        "        style_function=lambda f: {\"color\": \"#4caf50\", \"weight\": 2.5, \"opacity\": 0.9}\n",
        "    ).add_to(fg_xwalks)\n",
        "    fg_xwalks.add_to(m)\n",
        "\n",
        "# Controls\n",
        "folium.LayerControl(collapsed=False).add_to(m)\n",
        "m\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T_i3d1u_Cl29"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}